from itertools import combinations, chain

import numpy as np
from scipy.stats import gaussian_kde
import pandas as pd

from evaluation import sharpe_ratio
from evaluation.purged_cv import apply_purging_and_embargo
from utils.stats import KDEDist


def compute_pbo(perm_matrix: np.ndarray, eval_fn=sharpe_ratio, n_partitions=10):
    """
    Compute the probability of backtest overfitting for an optimization procedure used to select
    strategies or model configuration. See Bailey et al. [2017] for the original paper.

    :param perm_matrix: an TxN matrix of performance metrics (e.g. returns or PnL) matrix over
        T observations for N different strategies or model configurations
    :param eval_fn: aggregate performance metrics function over a set of metrics observations
    :param n_partitions: number of partitions to split observations before combining them combinatorially
        into train and test sets. Must be an even number
    :return: probability, rank logits, train sets metrics, test sets associated mtrics
    """
    assert n_partitions % 2 == 0
    n_obs, n_strats = perm_matrix.shape
    partition_size = n_obs // n_partitions
    rank_logits = []
    train_optimal_perm = []
    test_assoc_perm = []

    for partitions in combinations(range(n_partitions), n_partitions // 2):
        train_indices = list(chain.from_iterable(
            [list(range(int(p*partition_size), int((p+1)*partition_size))) for p in partitions]
        ))
        test_indices = [i for i in range(n_obs) if i not in train_indices]
        train_set = perm_matrix[train_indices, :]
        test_set = perm_matrix[test_indices, :]

        train_perm = eval_fn(train_set, axis=0)
        train_optimal_idx = np.argmax(train_perm)
        train_optimal_perm.append(train_perm[train_optimal_idx])

        test_perm = eval_fn(test_set, axis=0)
        test_assoc_perm.append(test_perm[train_optimal_idx])
        test_rank = 0
        for r, i in enumerate(np.argsort(test_perm)):
            if i == train_optimal_idx:
                test_rank = r
        test_rank /= test_perm.shape[0]
        test_rank_logit = np.log(test_rank/(1 - test_rank) + 1e-3)
        rank_logits.append(test_rank_logit)

    kde = gaussian_kde(rank_logits)
    kde_dist = KDEDist(kde)
    pbo = kde_dist.cdf(0)
    return pbo, rank_logits, train_optimal_perm, test_assoc_perm


class CombinatorialPurgedCV:
    """
    This class implements the combinatorial purged cross validation method, which improves over the walk forward
    validation method. It can generate multiple scenarios for backtesting instead of a single historical paths and
    each training set is equal in size and makes use of all information available.

    The given set of events are divided into num_groups. Each train/test split is generated by combinatorially
    choosing num_test_groups. Purging and embargo are applied to prevent leakage (see apply_purging_and_embargo method
    for more details).

    Multimple backtest paths are generated by combinatorially chaining test groups from different
    validation splits. Validation metrics can then be applied on each of these paths and averaged together.
    """

    def __init__(self, num_groups, num_test_groups, bar_times: pd.Series, event_times: pd.Series, embargo_pct=0.):
        self._n_groups = num_groups
        self._n_test_groups = num_test_groups

        self._bar_times = bar_times
        self._event_times = event_times
        self._embargo_pct = embargo_pct

        self._n_obs = event_times.shape[0]
        self._group_size = self._n_obs / self._n_groups
        # Lists of split indices where each group was selected for the test set
        self._split_of_test_group = [[] for _ in range(num_groups)]

    def split(self):
        """
        :return: (train indices, test_indices) for event_times
        """
        for split_idx, test_grps in enumerate(combinations(range(self._n_groups), self._n_test_groups)):
            test_indices = list(chain.from_iterable(
                list(range(int(g*self._group_size), int((g+1)*self._group_size)))
                for g in test_grps
            ))
            test_times = self._event_times.iloc[test_indices]

            train_times = apply_purging_and_embargo(self._event_times, test_times, self._bar_times, self._embargo_pct)
            train_indices = self._event_times.index.searchsorted(train_times.index)

            for g in test_grps:
                self._split_of_test_group[g].append(split_idx)

            yield train_indices, test_indices

    def get_backtest_paths(self):
        """
        :return: list of backtest path. Each path is a list of (test indices, split index)
        """
        num_paths = min(len(l) for l in self._split_of_test_group)
        for i in range(num_paths):
            path_splits = [l[i] for l in self._split_of_test_group]
            test_indices = list(
                list(range(int(g*self._group_size), int((g+1)*self._group_size)))
                for g in range(self._n_groups)
            )
            yield list(zip(test_indices, path_splits))
